"""
äº¤æ˜“æ˜ç»†å¯¼å…¥å¯¼å‡ºæœåŠ¡
æ”¯æŒCSVæ ¼å¼çš„äº¤æ˜“æ˜ç»†æ•°æ®å¯¼å…¥å¯¼å‡º
"""

import pandas as pd
from datetime import datetime
from typing import Optional, List, Dict, Any
from sqlalchemy.orm import Session
from sqlalchemy import and_
from io import StringIO

from app.models.base import TransactionDetail, FinancialAggregation
from app.services.aggregation_service import AggregationService


class TransactionImportExportService:
    """äº¤æ˜“æ˜ç»†å¯¼å…¥å¯¼å‡ºæœåŠ¡"""

    # CSVæ–‡ä»¶çš„æ ‡å‡†åˆ—å
    CSV_COLUMNS = [
        "äº¤æ˜“æ—¶é—´",
        "ç±»å‹", 
        "é‡‘é¢",
        "æ”¶æ”¯",
        "æ”¯ä»˜æ–¹å¼",
        "äº¤æ˜“å¯¹æ–¹",
        "å•†å“åç§°",
        "å¤‡æ³¨"
    ]

    @staticmethod
    def _clean_string_value(value) -> str:
        """
        æ¸…ç†å­—ç¬¦ä¸²å€¼ï¼Œå¤„ç†NaNã€Noneç­‰æƒ…å†µ
        
        Args:
            value: åŸå§‹å€¼
            
        Returns:
            æ¸…ç†åçš„å­—ç¬¦ä¸²
        """
        if pd.isna(value) or value is None:
            return ""
        
        str_value = str(value).strip()
        return "" if str_value.lower() == "nan" else str_value

    @staticmethod
    def _is_empty_value(value) -> bool:
        """
        åˆ¤æ–­å€¼æ˜¯å¦ä¸ºç©º
        
        Args:
            value: è¦æ£€æŸ¥çš„å€¼
            
        Returns:
            æ˜¯å¦ä¸ºç©º
        """
        if pd.isna(value) or value is None:
            return True
        
        str_value = str(value).strip()
        return str_value == "" or str_value.lower() == "nan"

    @staticmethod
    def export_to_csv(
        db: Session,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        output_path: Optional[str] = None
    ) -> str:
        """
        å¯¼å‡ºäº¤æ˜“æ˜ç»†ä¸ºCSVæ–‡ä»¶
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
            start_date: å¼€å§‹æ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è¿”å›CSVå†…å®¹å­—ç¬¦ä¸²
            
        Returns:
            CSVæ–‡ä»¶è·¯å¾„æˆ–CSVå†…å®¹å­—ç¬¦ä¸²
        """
        try:
            # æ„å»ºæŸ¥è¯¢
            query = db.query(TransactionDetail)
            
            # æ·»åŠ æ—¥æœŸè¿‡æ»¤
            if start_date:
                query = query.filter(TransactionDetail.transaction_time >= start_date)
            if end_date:
                # ç»“æŸæ—¥æœŸåŒ…å«å½“å¤©ï¼Œæ‰€ä»¥è¦åŠ ä¸€å¤©
                end_datetime = datetime.strptime(end_date, "%Y-%m-%d")
                query = query.filter(TransactionDetail.transaction_time < end_datetime.replace(hour=23, minute=59, second=59))
            
            # æŒ‰æ—¶é—´å€’åºæ’åˆ—
            transactions = query.order_by(TransactionDetail.transaction_time.desc()).all()
            
            # è½¬æ¢ä¸ºDataFrame
            data = []
            for transaction in transactions:
                data.append({
                    "äº¤æ˜“æ—¶é—´": transaction.transaction_time.strftime("%Y-%m-%d %H:%M:%S"),
                    "ç±»å‹": transaction.category,
                    "é‡‘é¢": transaction.amount,
                    "æ”¶æ”¯": transaction.income_expense_type,
                    "æ”¯ä»˜æ–¹å¼": transaction.payment_method or "",
                    "äº¤æ˜“å¯¹æ–¹": transaction.counterparty or "",
                    "å•†å“åç§°": transaction.item_name or "",
                    "å¤‡æ³¨": transaction.remarks or ""
                })
            
            df = pd.DataFrame(data, columns=TransactionImportExportService.CSV_COLUMNS)
            
            if output_path:
                # ä¿å­˜åˆ°æ–‡ä»¶
                df.to_csv(output_path, index=False, encoding='utf-8-sig')
                return output_path
            else:
                # è¿”å›CSVå­—ç¬¦ä¸²
                output = StringIO()
                df.to_csv(output, index=False, encoding='utf-8')
                return output.getvalue()
                
        except Exception as e:
            raise Exception(f"å¯¼å‡ºCSVå¤±è´¥: {str(e)}")

    @staticmethod
    def import_from_csv(
        db: Session,
        csv_content: str = None,
        csv_file_path: str = None,
        enable_deduplication: bool = True
    ) -> Dict[str, Any]:
        """
        ä»CSVå¯¼å…¥äº¤æ˜“æ˜ç»†æ•°æ®
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
            csv_content: CSVå†…å®¹å­—ç¬¦ä¸²
            csv_file_path: CSVæ–‡ä»¶è·¯å¾„
            enable_deduplication: æ˜¯å¦å¯ç”¨å»é‡
            
        Returns:
            å¯¼å…¥ç»“æœç»Ÿè®¡
        """
        try:
            if csv_content is not None:
                df = pd.read_csv(StringIO(csv_content), encoding='utf-8')
            elif csv_file_path:
                df = pd.read_csv(csv_file_path, encoding='utf-8')
            else:
                raise ValueError("å¿…é¡»æä¾›csv_contentæˆ–csv_file_path")
        except Exception as e:
            return {
                "success": False,
                "message": f"è¯»å–CSVå¤±è´¥: {str(e)}",
                "imported_count": 0,
                "skipped_count": 0,
                "duplicate_count": 0,
                "error_details": [],
                "duplicate_details": []
            }

        return TransactionImportExportService._import_dataframe(
            db=db,
            df=df,
            enable_deduplication=enable_deduplication
        )

    @staticmethod
    def import_from_dataframe(
        db: Session,
        df: pd.DataFrame,
        enable_deduplication: bool = True
    ) -> Dict[str, Any]:
        """ä»å·²ç»å‡†å¤‡å¥½çš„DataFrameå¯¼å…¥äº¤æ˜“æ˜ç»†æ•°æ®ã€‚"""
        return TransactionImportExportService._import_dataframe(
            db=db,
            df=df,
            enable_deduplication=enable_deduplication
        )

    @staticmethod
    def _import_dataframe(
        db: Session,
        df: pd.DataFrame,
        enable_deduplication: bool = True
    ) -> Dict[str, Any]:
        try:
            working_df = df.copy()

            validation_result = TransactionImportExportService._validate_csv_format(working_df)
            if not validation_result["valid"]:
                return {
                    "success": False,
                    "message": validation_result["message"],
                    "imported_count": 0,
                    "skipped_count": 0,
                    "duplicate_count": 0,
                    "error_details": [],
                    "duplicate_details": []
                }

            imported_count = 0
            skipped_count = 0
            duplicate_count = 0
            error_details: List[Dict[str, Any]] = []
            duplicate_details: List[Dict[str, Any]] = []

            for index, row in working_df.iterrows():
                try:
                    required_fields = ["äº¤æ˜“æ—¶é—´", "ç±»å‹", "é‡‘é¢", "æ”¶æ”¯"]
                    for field in required_fields:
                        if TransactionImportExportService._is_empty_value(row[field]):
                            raise ValueError(f"å¿…éœ€å­—æ®µ '{field}' ä¸ºç©º")

                    try:
                        transaction_time = pd.to_datetime(row["äº¤æ˜“æ—¶é—´"])
                    except Exception as e:
                        raise ValueError(f"äº¤æ˜“æ—¶é—´æ ¼å¼é”™è¯¯: {str(e)}")

                    try:
                        amount = float(row["é‡‘é¢"])
                        if amount < 0:
                            raise ValueError("é‡‘é¢ä¸èƒ½ä¸ºè´Ÿæ•°")
                    except ValueError as e:
                        if "could not convert" in str(e) or "invalid literal" in str(e):
                            raise ValueError("é‡‘é¢æ ¼å¼é”™è¯¯ï¼Œå¿…é¡»ä¸ºæ•°å­—")
                        raise e

                    category = TransactionImportExportService._clean_string_value(row["ç±»å‹"])
                    income_expense_type = TransactionImportExportService._clean_string_value(row["æ”¶æ”¯"])

                    if not category:
                        raise ValueError("äº¤æ˜“ç±»å‹ä¸èƒ½ä¸ºç©º")
                    if not income_expense_type:
                        raise ValueError("æ”¶æ”¯ç±»å‹ä¸èƒ½ä¸ºç©º")

                    if enable_deduplication:
                        counterparty_for_check = TransactionImportExportService._clean_string_value(row["äº¤æ˜“å¯¹æ–¹"])
                        item_name_for_check = TransactionImportExportService._clean_string_value(row["å•†å“åç§°"])

                        is_duplicate = TransactionImportExportService._check_duplicate(
                            db, transaction_time, amount, counterparty_for_check, item_name_for_check
                        )
                        if is_duplicate:
                            duplicate_count += 1
                            duplicate_details.append({
                                "row": index + 2,
                                "transaction_time": str(transaction_time),
                                "amount": amount,
                                "counterparty": TransactionImportExportService._clean_string_value(row["äº¤æ˜“å¯¹æ–¹"]),
                                "item_name": TransactionImportExportService._clean_string_value(row["å•†å“åç§°"]),
                                "reason": "æ•°æ®é‡å¤ï¼šç›¸åŒæ—¶é—´ã€é‡‘é¢ã€äº¤æ˜“å¯¹æ–¹å’Œå•†å“åç§°çš„è®°å½•å·²å­˜åœ¨"
                            })
                            continue

                    payment_method = TransactionImportExportService._clean_string_value(row["æ”¯ä»˜æ–¹å¼"])
                    counterparty = TransactionImportExportService._clean_string_value(row["äº¤æ˜“å¯¹æ–¹"])
                    item_name = TransactionImportExportService._clean_string_value(row["å•†å“åç§°"])
                    remarks = TransactionImportExportService._clean_string_value(row["å¤‡æ³¨"])

                    transaction = TransactionDetail(
                        transaction_time=transaction_time,
                        category=category,
                        amount=amount,
                        income_expense_type=income_expense_type,
                        payment_method=payment_method if payment_method else None,
                        counterparty=counterparty if counterparty else None,
                        item_name=item_name if item_name else None,
                        remarks=remarks if remarks else None
                    )

                    db.add(transaction)
                    imported_count += 1

                except Exception as e:
                    error_message = str(e)
                    print(f"å¤„ç†ç¬¬{index+2}è¡Œæ•°æ®å¤±è´¥: {error_message}")
                    skipped_count += 1
                    error_details.append({
                        "row": index + 2,
                        "data": {
                            "äº¤æ˜“æ—¶é—´": str(row.get("äº¤æ˜“æ—¶é—´", "")),
                            "ç±»å‹": str(row.get("ç±»å‹", "")),
                            "é‡‘é¢": str(row.get("é‡‘é¢", "")),
                            "æ”¶æ”¯": str(row.get("æ”¶æ”¯", "")),
                            "æ”¯ä»˜æ–¹å¼": str(row.get("æ”¯ä»˜æ–¹å¼", "")),
                            "äº¤æ˜“å¯¹æ–¹": str(row.get("äº¤æ˜“å¯¹æ–¹", "")),
                            "å•†å“åç§°": str(row.get("å•†å“åç§°", "")),
                            "å¤‡æ³¨": str(row.get("å¤‡æ³¨", ""))
                        },
                        "reason": error_message
                    })
                    continue

            db.commit()
            TransactionImportExportService._refresh_financial_aggregation(db)

            return {
                "success": True,
                "message": "æ•°æ®å¯¼å…¥æˆåŠŸ",
                "imported_count": imported_count,
                "skipped_count": skipped_count,
                "duplicate_count": duplicate_count,
                "error_details": error_details,
                "duplicate_details": duplicate_details
            }

        except Exception as e:
            db.rollback()
            return {
                "success": False,
                "message": f"æ•°æ®å¯¼å…¥å¤±è´¥: {str(e)}",
                "imported_count": 0,
                "skipped_count": 0,
                "duplicate_count": 0,
                "error_details": [],
                "duplicate_details": []
            }

    @staticmethod
    def _validate_csv_format(df: pd.DataFrame) -> Dict[str, Any]:
        """
        éªŒè¯CSVæ–‡ä»¶æ ¼å¼
        
        Args:
            df: pandas DataFrame
            
        Returns:
            éªŒè¯ç»“æœ
        """
        required_columns = TransactionImportExportService.CSV_COLUMNS
        
        # æ£€æŸ¥å¿…éœ€çš„åˆ—æ˜¯å¦å­˜åœ¨
        missing_columns = set(required_columns) - set(df.columns)
        if missing_columns:
            return {
                "valid": False,
                "message": f"ç¼ºå°‘å¿…éœ€çš„åˆ—: {', '.join(missing_columns)}"
            }
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®è¡Œ
        if len(df) == 0:
            return {
                "valid": False,
                "message": "CSVæ–‡ä»¶æ²¡æœ‰æ•°æ®è¡Œ"
            }
        
        # åŸºæœ¬éªŒè¯é€šè¿‡ï¼Œå…·ä½“çš„æ•°æ®éªŒè¯åœ¨å¯¼å…¥è¿‡ç¨‹ä¸­è¿›è¡Œ
        return {"valid": True, "message": "CSVæ ¼å¼æ­£ç¡®"}

    @staticmethod
    def _check_duplicate(
        db: Session,
        transaction_time: datetime,
        amount: float,
        counterparty: str,
        item_name: str
    ) -> bool:
        """
        æ£€æŸ¥é‡å¤äº¤æ˜“
        æ ¹æ®æ—¶é—´ã€é‡‘é¢ã€äº¤æ˜“å¯¹æ–¹ã€å•†å“åç§°åˆ¤æ–­æ˜¯å¦ä¸ºé‡å¤äº¤æ˜“
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
            transaction_time: äº¤æ˜“æ—¶é—´
            amount: é‡‘é¢
            counterparty: äº¤æ˜“å¯¹æ–¹ï¼ˆå·²æ¸…ç†ï¼‰
            item_name: å•†å“åç§°ï¼ˆå·²æ¸…ç†ï¼‰
            
        Returns:
            æ˜¯å¦ä¸ºé‡å¤äº¤æ˜“
        """
        # åŸºç¡€æŸ¥è¯¢æ¡ä»¶ï¼šæ—¶é—´å’Œé‡‘é¢
        base_query = db.query(TransactionDetail).filter(
            and_(
                TransactionDetail.transaction_time == transaction_time,
                TransactionDetail.amount == amount
            )
        )
        
        # æ„å»ºäº¤æ˜“å¯¹æ–¹çš„æŸ¥è¯¢æ¡ä»¶
        counterparty_conditions = []
        
        if counterparty:
            # ç²¾ç¡®åŒ¹é…æ¸…ç†åçš„å€¼
            counterparty_conditions.append(TransactionDetail.counterparty == counterparty)
            # è¿˜è¦åŒ¹é…å¯èƒ½å­˜åœ¨å°¾éšç©ºæ ¼çš„ç‰ˆæœ¬
            counterparty_conditions.append(TransactionDetail.counterparty.like(f"{counterparty}%"))
        else:
            counterparty_conditions.append(TransactionDetail.counterparty.is_(None))
        
        # æ„å»ºå•†å“åç§°çš„æŸ¥è¯¢æ¡ä»¶
        item_name_conditions = []
        
        if item_name:
            # ç²¾ç¡®åŒ¹é…æ¸…ç†åçš„å€¼
            item_name_conditions.append(TransactionDetail.item_name == item_name)
            # è¿˜è¦åŒ¹é…å¯èƒ½å­˜åœ¨å°¾éšç©ºæ ¼çš„ç‰ˆæœ¬
            item_name_conditions.append(TransactionDetail.item_name.like(f"{item_name}%"))
        else:
            item_name_conditions.append(TransactionDetail.item_name.is_(None))
        
        # ç»„åˆæŸ¥è¯¢æ¡ä»¶
        from sqlalchemy import or_
        
        final_query = base_query.filter(
            or_(*counterparty_conditions),
            or_(*item_name_conditions)
        )
        
        result = final_query.first()
        return result is not None

    @staticmethod
    def _refresh_financial_aggregation(db: Session):
        """
        åˆ·æ–°è´¢åŠ¡èšåˆæ•°æ®
        æ¸…ç©ºç°æœ‰èšåˆæ•°æ®å¹¶é‡æ–°ç”Ÿæˆ
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
        """
        try:
            print("ğŸ”„ å¼€å§‹åˆ·æ–°è´¢åŠ¡èšåˆæ•°æ®...")
            
            # æ¸…ç©ºç°æœ‰èšåˆæ•°æ®
            db.query(FinancialAggregation).delete()
            db.commit()
            
            # é‡æ–°èšåˆæ‰€æœ‰æ•°æ®
            result = AggregationService.aggregate_monthly_data(db)
            
            print(f"âœ… è´¢åŠ¡èšåˆæ•°æ®åˆ·æ–°å®Œæˆ: {result}")
            
        except Exception as e:
            print(f"âŒ è´¢åŠ¡èšåˆæ•°æ®åˆ·æ–°å¤±è´¥: {str(e)}")
            db.rollback()
            raise

    @staticmethod
    def get_csv_template() -> str:
        """
        è·å–CSVæ¨¡æ¿
        
        Returns:
            CSVæ¨¡æ¿å­—ç¬¦ä¸²
        """
        # åˆ›å»ºç¤ºä¾‹æ•°æ®
        sample_data = [
            {
                "äº¤æ˜“æ—¶é—´": "2024-01-15 14:30:00",
                "ç±»å‹": "é¤é¥®", 
                "é‡‘é¢": 25.50,
                "æ”¶æ”¯": "æ”¯å‡º",
                "æ”¯ä»˜æ–¹å¼": "æ”¯ä»˜å®",
                "äº¤æ˜“å¯¹æ–¹": "æŸé¤å…",
                "å•†å“åç§°": "åˆé¤",
                "å¤‡æ³¨": "å’ŒåŒäº‹èšé¤"
            },
            {
                "äº¤æ˜“æ—¶é—´": "2024-01-15 09:00:00",
                "ç±»å‹": "å·¥èµ„", 
                "é‡‘é¢": 8000.00,
                "æ”¶æ”¯": "æ”¶å…¥",
                "æ”¯ä»˜æ–¹å¼": "é“¶è¡Œè½¬è´¦",
                "äº¤æ˜“å¯¹æ–¹": "å…¬å¸",
                "å•†å“åç§°": "æœˆå·¥èµ„",
                "å¤‡æ³¨": "1æœˆä»½å·¥èµ„"
            }
        ]
        
        df = pd.DataFrame(sample_data, columns=TransactionImportExportService.CSV_COLUMNS)
        output = StringIO()
        df.to_csv(output, index=False, encoding='utf-8')
        return output.getvalue()
